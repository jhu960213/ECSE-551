{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Imports**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished importing!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import math as ma\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "print(\"Finished importing!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Mounting Google Drive**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/myDrive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Restrict the Number of Training Samples for Testing Purposes**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Removes samples from the training set until only remaining_samples samples remain.\n",
    "def sampleReduction(training_set,remaining_samples):\n",
    "  count = len(training_set) - remaining_samples\n",
    "\n",
    "  while count > 0:\n",
    "    training_set.pop()\n",
    "    count -= 1\n",
    "\n",
    "  return training_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Importing Data Sets**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of training samples: 11582\n",
      "Reduced number of training samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv('/content/myDrive/My Drive/ECSE_551_Machine_Learning/train.csv')\n",
    "# df_test = pd.read_csv('/content/myDrive/My Drive/ECSE_551_Machine_Learning/test.csv')\n",
    "# df_train = pd.read_csv('C:/Users/AlexG35/Desktop/GitHub/TextClassification/train.csv')\n",
    "# df_test = pd.read_csv('C:/Users/AlexG35/Desktop/GitHub/TextClassification/test.csv')\n",
    "# df_train = pd.read_csv('/Users/jhu69/Desktop/Github/TextClassification/train.csv')\n",
    "# df_test = pd.read_csv('/Users/jhu69/Desktop/Github/TextClassification/test.csv')\n",
    "df_train = pd.read_csv('C:/Users/karan/Desktop/Masters/Codes/CodeRemote/GitHub_codes/Under_Grad_mSpice/DP_teams/TextClassification/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/karan/Desktop/Masters/Codes/CodeRemote/GitHub_codes/Under_Grad_mSpice/DP_teams/TextClassification/test.csv')\n",
    "\n",
    "# Converting DataFrames to lists.\n",
    "training_set = df_train.values.tolist()\n",
    "test_set = df_test.values.tolist()\n",
    "\n",
    "# Shuffling the training and test data sets\n",
    "rand.shuffle(training_set)\n",
    "rand.shuffle(test_set)\n",
    "\n",
    "#--------Restrict the Number of Training Samples for Testing Purposes**---------\n",
    "print(\"Original number of training samples: \" + str(len(training_set)))\n",
    "training_set = sampleReduction(training_set, 2000)\n",
    "print(\"Reduced number of training samples: \" + str(len(training_set)))\n",
    "#--------Restrict the Number of Training Samples for Testing Purposes**---------\n",
    "\n",
    "# print(training_set[0])\n",
    "\n",
    "# Splitting the sets into inputs and outputs.\n",
    "training_set_in = []\n",
    "training_set_out = []\n",
    "test_set_in = []\n",
    "# Note: no outputs for test set - must predict them.\n",
    "\n",
    "for sample in training_set:\n",
    "  training_set_in.append(sample[0])\n",
    "  training_set_out.append(sample[1])\n",
    "\n",
    "for sample in test_set:\n",
    "  test_set_in.append(sample[1])\n",
    "\n",
    "# print(training_set_out)\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Parsing**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Dictionary of relevant characters in a word.\n",
    "# Returns true if the character is a *LOWERCASE* letter, number or accepted \n",
    "# special character, else returns false.\n",
    "def isAlphanumeric (char):\n",
    "  switcher = {\n",
    "    'a': True,\n",
    "    'b': True,\n",
    "    'c': True,\n",
    "    'd': True,\n",
    "    'e': True,\n",
    "    'f': True,\n",
    "    'g': True,\n",
    "    'h': True,\n",
    "    'i': True,\n",
    "    'j': True,\n",
    "    'k': True,\n",
    "    'l': True,\n",
    "    'm': True,\n",
    "    'n': True,\n",
    "    'o': True,\n",
    "    'p': True,\n",
    "    'q': True,\n",
    "    'r': True,\n",
    "    's': True,\n",
    "    't': True,\n",
    "    'u': True,\n",
    "    'v': True,\n",
    "    'w': True,\n",
    "    'x': True,\n",
    "    'y': True,\n",
    "    'z': True,\n",
    "    '0': True,\n",
    "    '1': True,\n",
    "    '2': True,\n",
    "    '3': True,\n",
    "    '4': True,\n",
    "    '5': True,\n",
    "    '6': True,\n",
    "    '7': True,\n",
    "    '8': True,\n",
    "    '9': True,\n",
    "    '\\'': True,   #Apostrophe\n",
    "    '$': True,\n",
    "    #'@': True,    #For email addresses\n",
    "    #'_': True, \n",
    "    '-': True,\n",
    "    #'/': True     #For websites\n",
    "  }\n",
    "  return switcher.get(char,False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Returns true if character is a number, false otherwise.\n",
    "def isNumber(char):\n",
    "  switcher = {\n",
    "    '0': True,\n",
    "    '1': True,\n",
    "    '2': True,\n",
    "    '3': True,\n",
    "    '4': True,\n",
    "    '5': True,\n",
    "    '6': True,\n",
    "    '7': True,\n",
    "    '8': True,\n",
    "    '9': True,\n",
    "  }\n",
    "  return switcher.get(char,False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Joins the characters in a list of characters together to form a string.\n",
    "def mergeCharacters(char_array):\n",
    "  # Intialize string to \"\"\n",
    "  s = \"\"\n",
    "\n",
    "  return(s.join(char_array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Parses the input string and returns its words in the form of a list of strings.\n",
    "def parseLine(line):\n",
    "  line = line.lower()     # Converts all letters to lowercase\n",
    "  char_array = list(line) # Converts the line to an list of characters\n",
    "  words_array = [[]]      # List of a list of characters that for words\n",
    "  words = []              # List of words\n",
    "  word_idx = 0      # Index of the current word\n",
    "\n",
    "  # Creates a list of words made out of characters (i.e. a list of lists of char).\n",
    "  for char in char_array:\n",
    "    if isAlphanumeric(char):\n",
    "      temp = words_array[word_idx]    # temp is the current word\n",
    "      temp.append(char)\n",
    "      #char_idx += 1\n",
    "    else:\n",
    "      if words_array[word_idx]:     # True if word contains at least 1 character\n",
    "        words_array.append([])      # Appending the next empty word to be filled\n",
    "        word_idx += 1               # Index into the next word\n",
    "\n",
    "  # Creates a list of words made out of strings.\n",
    "  for word in words_array:\n",
    "    if word:                        # If word is non-empty. Always true (hopefully) except for the last one)            \n",
    "      dollar_sign = False\n",
    "      contains_number = False\n",
    "      for char in word:\n",
    "        if char == '$':                \n",
    "          dollar_sign = True\n",
    "        elif isNumber(char):\n",
    "          contains_number = True\n",
    "      if dollar_sign:\n",
    "        words.append(\"money\")       # Substitute any money amount with simply \"money\"\n",
    "      elif contains_number:\n",
    "        words.append(\"number\")      # Substitute any number with simply \"number\"\n",
    "      else:\n",
    "        words.append(mergeCharacters(word))  # Merge the characters of the word into a string\n",
    "\n",
    "  return words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted training and test sets into a list of lists of words!\n",
      "Each row in X_words corresponds to a training sample represented as a list of words\n"
     ]
    }
   ],
   "source": [
    "# Converts the inputs of the training and test sets into lists of words in the form of strings.\n",
    "X_words = []\n",
    "Xtest_words = []\n",
    "\n",
    "for sample in training_set_in:\n",
    "  X_words.append(parseLine(sample))\n",
    "\n",
    "# NO NEED TO PARSE THE TEST SET FOR NOW\n",
    "# for sample in test_set_in:\n",
    "#  Xtest_words.append(parseLine(sample))\n",
    "print(\"Converted training and test sets into a list of lists of words!\")\n",
    "print(\"Each row in X_words corresponds to a training sample represented as a list of words\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Feature Removal and Visualization**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#@title Dictionary of Irrelevant Words (need to run this)\n",
    "# Dictionary of irrelevant words.\n",
    "# Returns true if the *LOWERCASE* word is irrelevant, else returns false.\n",
    "def isIrrelevant (word):\n",
    "  switcher = {\n",
    "    # All pronouns and associated words\n",
    "    \"i\": True,\n",
    "    \"i'll\": True,\n",
    "    \"i'd\": True,\n",
    "    \"i'm\": True,\n",
    "    \"i've\": True,\n",
    "    \"ive\": True,\n",
    "    \"me\": True,\n",
    "    \"myself\": True,\n",
    "    \"you\": True,\n",
    "    \"you'll\": True,\n",
    "    \"you'd\": True,\n",
    "    \"you're\": True,\n",
    "    \"you've\": True,\n",
    "    \"yourself\": True,\n",
    "    \"he\": True,\n",
    "    \"he'll\": True,\n",
    "    \"he'd\": True,\n",
    "    \"he's\": True,\n",
    "    \"him\": True,\n",
    "    \"she\": True,\n",
    "    \"she'll\": True,\n",
    "    \"she'd\": True,\n",
    "    \"she's\": True,\n",
    "    \"her\": True,\n",
    "    \"it\": True,\n",
    "    \"it'll\": True,\n",
    "    \"it'd\": True,\n",
    "    \"it's\": True,\n",
    "    \"itself\": True,\n",
    "    \"oneself\": True,\n",
    "    \"we\": True,\n",
    "    \"we'll\": True,\n",
    "    \"we'd\": True,\n",
    "    \"we're\": True,\n",
    "    \"we've\": True,\n",
    "    \"us\": True,\n",
    "    \"ourselves\": True,\n",
    "    \"they\": True,\n",
    "    \"they'll\": True,\n",
    "    \"they'd\": True,\n",
    "    \"they're\": True,\n",
    "    \"they've\": True,\n",
    "    \"them\": True,\n",
    "    \"themselves\": True,            \n",
    "    \"everyone\": True,\n",
    "    \"everyone's\": True,\n",
    "    \"everybody\": True,\n",
    "    \"everybody's\": True,\n",
    "    \"someone\": True,\n",
    "    \"someone's\": True,\n",
    "    \"somebody\": True,\n",
    "    \"somebody's\": True,\n",
    "    \"nobody\": True,\n",
    "    \"nobody's\": True,\n",
    "    \"anyone\": True,\n",
    "    \"anyone's\": True,\n",
    "    \"everything\": True,\n",
    "    \"everything's\": True,\n",
    "    \"something\": True,\n",
    "    \"something's\": True,\n",
    "    \"nothing\": True,\n",
    "    \"nothing's\": True,\n",
    "    \"anything\": True,\n",
    "    \"anything's\": True,\n",
    "    # All determiners and associated words\n",
    "    \"a\": True,\n",
    "    \"an\": True,\n",
    "    \"the\": True,\n",
    "    \"this\": True,\n",
    "    \"that\": True,\n",
    "    \"that's\": True,\n",
    "    \"these\": True,\n",
    "    \"those\": True,\n",
    "    \"my\": True,\n",
    "    #\"mine\": True,   #Omitted since mine can refer to something else\n",
    "    \"your\": True,\n",
    "    \"yours\": True,\n",
    "    \"his\": True,\n",
    "    \"hers\": True,\n",
    "    \"its\": True,\n",
    "    \"our\": True,\n",
    "    \"ours\": True,\n",
    "    \"own\": True,\n",
    "    \"their\": True,\n",
    "    \"theirs\": True,\n",
    "    \"few\": True,\n",
    "    \"much\": True,\n",
    "    \"many\": True,\n",
    "    \"lot\": True,\n",
    "    \"lots\": True,\n",
    "    \"some\": True,\n",
    "    \"any\": True,\n",
    "    \"enough\": True,\n",
    "    \"all\": True,\n",
    "    \"both\": True,\n",
    "    \"half\": True,\n",
    "    \"either\": True,\n",
    "    \"neither\": True,\n",
    "    \"each\": True,\n",
    "    \"every\": True,\n",
    "    \"certain\": True,\n",
    "    \"other\": True,\n",
    "    \"another\": True,\n",
    "    \"such\": True,\n",
    "    \"several\": True,\n",
    "    \"multiple\": True,\n",
    "    # \"what\": True,    #Dealt with later on\n",
    "    \"rather\": True,\n",
    "    \"quite\": True,\n",
    "    # All prepositions\n",
    "    \"aboard\": True,\n",
    "    \"about\": True,\n",
    "    \"above\": True,\n",
    "    \"across\": True,\n",
    "    \"after\": True,\n",
    "    \"against\": True,\n",
    "    \"along\": True,\n",
    "    \"amid\": True,\n",
    "    \"amidst\": True,\n",
    "    \"among\": True,\n",
    "    \"amongst\": True,\n",
    "    \"anti\": True,\n",
    "    \"around\": True,\n",
    "    \"as\": True,\n",
    "    \"at\": True,\n",
    "    \"away\": True,\n",
    "    \"before\": True,\n",
    "    \"behind\": True,\n",
    "    \"below\": True,\n",
    "    \"beneath\": True,\n",
    "    \"beside\": True,\n",
    "    \"besides\": True,\n",
    "    \"between\": True,\n",
    "    \"beyond\": True,\n",
    "    \"but\": True,\n",
    "    \"by\": True,\n",
    "    \"concerning\": True,\n",
    "    \"considering\": True,\n",
    "    \"despite\": True,\n",
    "    \"down\": True,\n",
    "    \"during\": True,\n",
    "    \"except\": True,\n",
    "    \"excepting\": True,\n",
    "    \"excluding\": True,\n",
    "    \"far\": True,\n",
    "    \"following\": True,\n",
    "    \"for\": True,\n",
    "    \"from\": True,\n",
    "    \"here\": True,\n",
    "    \"here's\": True,\n",
    "    \"in\": True,\n",
    "    \"inside\": True,\n",
    "    \"into\": True,\n",
    "    \"left\": True,\n",
    "    \"like\": True,\n",
    "    \"minus\": True,\n",
    "    \"near\": True,\n",
    "    \"of\": True,\n",
    "    \"off\": True,\n",
    "    \"on\": True,\n",
    "    \"onto\": True,\n",
    "    \"opposite\": True,\n",
    "    \"out\": True,\n",
    "    \"outside\": True,\n",
    "    \"over\": True,\n",
    "    \"past\": True,\n",
    "    \"per\": True,\n",
    "    \"plus\": True,\n",
    "    \"regarding\": True,\n",
    "    \"right\": True,\n",
    "    #\"round\": True,   #Omitted\n",
    "    #\"save\": True,    #Omitted\n",
    "    \"since\": True,\n",
    "    \"than\": True,\n",
    "    \"there\": True,\n",
    "    \"there's\": True,\n",
    "    \"through\": True,\n",
    "    \"to\": True,\n",
    "    \"toward\": True,\n",
    "    \"towards\": True,\n",
    "    \"under\": True,\n",
    "    \"underneath\": True,\n",
    "    \"unlike\": True,\n",
    "    \"until\": True,\n",
    "    \"up\": True,\n",
    "    \"upon\": True,\n",
    "    \"versus\": True,\n",
    "    \"via\": True,\n",
    "    \"with\": True,\n",
    "    \"within\": True,\n",
    "    \"without\": True,\n",
    "    # Irrelevant verbs\n",
    "    \"may\": True,\n",
    "    \"might\": True,\n",
    "    \"will\": True,\n",
    "    \"won't\": True,\n",
    "    \"would\": True,\n",
    "    \"wouldn't\": True,\n",
    "    \"can\": True,\n",
    "    \"can't\": True,\n",
    "    \"cannot\": True,\n",
    "    \"could\": True,\n",
    "    \"couldn't\": True,\n",
    "    \"should\": True,\n",
    "    \"shouldn't\": True,\n",
    "    \"must\": True,\n",
    "    \"must've\": True,\n",
    "    \"be\": True,\n",
    "    \"being\": True,\n",
    "    \"been\": True,\n",
    "    \"am\": True,\n",
    "    \"are\": True,\n",
    "    \"aren't\": True,\n",
    "    \"ain't\": True,\n",
    "    \"is\": True,\n",
    "    \"isn't\": True,\n",
    "    \"was\": True,\n",
    "    \"wasn't\": True,\n",
    "    \"were\": True,\n",
    "    \"weren't\": True,\n",
    "    \"do\": True,\n",
    "    \"doing\": True,\n",
    "    \"don't\": True,\n",
    "    \"does\": True,\n",
    "    \"doesn't\": True,\n",
    "    \"did\": True,\n",
    "    \"didn't\": True,\n",
    "    \"done\": True,\n",
    "    \"have\": True,\n",
    "    \"haven't\": True,\n",
    "    \"having\": True,\n",
    "    \"has\": True,\n",
    "    \"hasn't\": True,\n",
    "    \"had\": True,\n",
    "    \"hadn't\": True,\n",
    "    \"get\": True,\n",
    "    \"getting\": True,\n",
    "    \"gets\": True,\n",
    "    \"got\": True,\n",
    "    \"gotten\": True,\n",
    "    \"go\": True,\n",
    "    \"going\": True,\n",
    "    \"gonna\": True,\n",
    "    \"goes\": True,\n",
    "    \"went\": True,\n",
    "    \"gone\": True,\n",
    "    \"make\": True,\n",
    "    \"making\": True,\n",
    "    \"makes\": True,\n",
    "    \"made\": True,\n",
    "    \"take\": True,\n",
    "    \"taking\": True,\n",
    "    \"takes\": True,\n",
    "    \"took\": True,\n",
    "    \"taken\": True,\n",
    "    \"need\": True,\n",
    "    \"needing\": True,\n",
    "    \"needs\": True,\n",
    "    \"needed\": True,\n",
    "    \"use\": True,\n",
    "    \"using\": True,\n",
    "    \"uses\": True,\n",
    "    \"used\": True,\n",
    "    \"want\": True,\n",
    "    \"wanna\": True,\n",
    "    \"wanting\": True,\n",
    "    \"wants\": True,\n",
    "    \"let\": True,\n",
    "    \"lets\": True,\n",
    "    \"letting\": True,\n",
    "    \"let's\": True,\n",
    "    \"suppose\": True,\n",
    "    \"supposing\": True,\n",
    "    \"supposes\": True,\n",
    "    \"supposed\": True,\n",
    "    \"seem\": True,\n",
    "    \"seeming\": True,\n",
    "    \"seems\": True,\n",
    "    \"seemed\": True,\n",
    "    \"say\": True,\n",
    "    \"saying\": True,\n",
    "    \"says\": True,\n",
    "    \"said\": True,\n",
    "    \"know\": True,\n",
    "    \"knowing\": True,\n",
    "    \"knows\": True,\n",
    "    \"knew\": True,\n",
    "    \"known\": True,\n",
    "    \"look\": True,\n",
    "    \"looking\": True,\n",
    "    \"looked\": True,\n",
    "    \"think\": True,\n",
    "    \"thinking\": True,\n",
    "    \"thinks\": True,\n",
    "    \"thought\": True,\n",
    "    \"feel\": True,\n",
    "    \"feels\": True,\n",
    "    \"felt\": True,\n",
    "    \"based\": True,\n",
    "    \"put\": True,\n",
    "    \"puts\": True,\n",
    "    #\"wanted\": True   #Omitted since the advective is relevant\n",
    "    # Question words and associated words\n",
    "    \"who\": True,\n",
    "    \"who's\": True,\n",
    "    \"who've\": True,\n",
    "    \"who'd\": True,\n",
    "    \"whoever\": True,\n",
    "    \"whoever's\": True,\n",
    "    \"whom\": True,\n",
    "    \"whomever\": True,\n",
    "    \"whomever's\": True,\n",
    "    \"whose\": True,\n",
    "    \"whosever\": True,\n",
    "    \"whosever's\": True,\n",
    "    \"when\": True,\n",
    "    \"whenever\": True,\n",
    "    \"which\": True,\n",
    "    \"whichever\": True,\n",
    "    \"where\": True,\n",
    "    \"where's\": True,\n",
    "    \"where'd\": True,\n",
    "    \"wherever\": True,\n",
    "    \"why\": True,\n",
    "    \"why's\": True,\n",
    "    \"why'd\": True,\n",
    "    \"whyever\": True,\n",
    "    \"what\": True,\n",
    "    \"what's\": True,\n",
    "    \"whatever\": True,\n",
    "    \"whence\": True,\n",
    "    \"how\": True,\n",
    "    \"how's\": True,\n",
    "    \"how'd\": True,\n",
    "    \"however\": True,\n",
    "    \"whether\": True,\n",
    "    \"whatsoever\": True,\n",
    "    # Connector words and irrelevant adverbs\n",
    "    \"and\": True,\n",
    "    \"or\": True,\n",
    "    \"not\": True,\n",
    "    \"because\": True,\n",
    "    \"also\": True,\n",
    "    \"always\": True,\n",
    "    \"never\": True,\n",
    "    \"only\": True,\n",
    "    \"really\": True,\n",
    "    \"very\": True,\n",
    "    \"greatly\": True,\n",
    "    \"extremely\": True,\n",
    "    \"somewhat\": True,\n",
    "    \"no\": True,\n",
    "    \"nope\": True,\n",
    "    \"nah\": True,\n",
    "    \"yes\": True,\n",
    "    \"yep\": True,\n",
    "    \"yeh\": True,\n",
    "    \"yeah\": True,\n",
    "    \"maybe\": True,\n",
    "    \"perhaps\": True,\n",
    "    \"more\": True,\n",
    "    \"most\": True,\n",
    "    \"less\": True,\n",
    "    \"least\": True,\n",
    "    \"good\": True,\n",
    "    \"great\": True,\n",
    "    \"well\": True,\n",
    "    \"better\": True,\n",
    "    \"best\": True,\n",
    "    \"bad\": True,\n",
    "    \"worse\": True,\n",
    "    \"worst\": True,\n",
    "    \"too\": True,\n",
    "    \"thru\": True,\n",
    "    \"though\": True,\n",
    "    \"although\": True,\n",
    "    \"yet\": True,\n",
    "    \"already\": True,\n",
    "    \"then\": True,\n",
    "    \"even\": True,\n",
    "    \"now\": True,\n",
    "    \"sometimes\": True,\n",
    "    \"still\": True,\n",
    "    \"together\": True,\n",
    "    \"altogether\": True,\n",
    "    \"entirely\": True,\n",
    "    \"fully\": True,\n",
    "    \"entire\": True,\n",
    "    \"whole\": True,\n",
    "    \"completely\": True,\n",
    "    \"utterly\": True,\n",
    "    \"seemingly\": True,\n",
    "    \"apparently\": True,\n",
    "    \"clearly\": True,\n",
    "    \"obviously\": True,\n",
    "    \"actually\": True,\n",
    "    \"actual\": True,\n",
    "    \"usually\": True,\n",
    "    \"usual\": True,\n",
    "    \"literally\": True,\n",
    "    \"honestly\": True,\n",
    "    \"absolutely\": True,\n",
    "    \"definitely\": True,\n",
    "    \"generally\": True,\n",
    "    \"totally\": True,\n",
    "    \"finally\": True,\n",
    "    \"basically\": True,\n",
    "    \"essentially\": True,\n",
    "    \"fundamentally\": True,\n",
    "    \"automatically\": True,\n",
    "    \"immediately\": True,\n",
    "    \"necessarily\": True,\n",
    "    \"primarily\": True,\n",
    "    \"normally\": True,\n",
    "    \"perfectly\": True,\n",
    "    \"constantly\": True,\n",
    "    \"particularly\": True,\n",
    "    \"eventually\": True,\n",
    "    \"hopefully\": True,\n",
    "    \"mainly\": True,\n",
    "    \"typically\": True,\n",
    "    \"specifically\": True,\n",
    "    \"differently\": True,\n",
    "    \"appropriately\": True,\n",
    "    \"plenty\": True,\n",
    "    \"certainly\": True,\n",
    "    \"unfortunately\": True,\n",
    "    \"ultimately\": True,\n",
    "    \"unlikely\": True,\n",
    "    \"likely\": True,\n",
    "    \"potentially\": True,\n",
    "    \"fortunately\": True,\n",
    "    \"personally\": True,\n",
    "    \"directly\": True,\n",
    "    \"indirectly\": True,\n",
    "    \"nearly\": True,\n",
    "    \"closely\": True,\n",
    "    \"slightly\": True,\n",
    "    \"probably\": True,\n",
    "    \"possibly\": True,\n",
    "    \"especially\": True,\n",
    "    \"frequently\": True,\n",
    "    \"often\": True,\n",
    "    \"oftentimes\": True,\n",
    "    \"seldom\": True,\n",
    "    \"rarely\": True,\n",
    "    \"sure\": True,\n",
    "    \"while\": True,\n",
    "    \"whilst\": True,\n",
    "    \"able\": True,\n",
    "    \"unable\": True,\n",
    "    \"else\": True,\n",
    "    \"ever\": True,\n",
    "    \"once\": True,\n",
    "    \"twice\": True,\n",
    "    \"thrice\": True,\n",
    "    \"almost\": True,\n",
    "    \"again\": True,\n",
    "    \"instead\": True,\n",
    "    \"next\": True,\n",
    "    \"previous\": True,\n",
    "    \"unless\": True,\n",
    "    \"somehow\": True,\n",
    "    \"anyhow\": True,\n",
    "    \"anywhere\": True,\n",
    "    \"somewhere\": True,\n",
    "    \"everywhere\": True,\n",
    "    \"nowhere\": True,\n",
    "    \"further\": True,\n",
    "    \"anymore\": True,\n",
    "    \"later\": True,\n",
    "    \"ago\": True,\n",
    "    \"ahead\": True,\n",
    "    \"just\": True,\n",
    "    \"same\": True,\n",
    "    \"different\": True,\n",
    "    \"big\": True,\n",
    "    \"small\": True,\n",
    "    \"little\": True,\n",
    "    \"tiny\": True,\n",
    "    \"large\": True,\n",
    "    \"huge\": True,\n",
    "    \"pretty\": True,\n",
    "    \"mostly\": True,\n",
    "    \"anyway\": True,\n",
    "    \"anyways\": True,\n",
    "    \"otherwise\": True,\n",
    "    \"regardless\": True,\n",
    "    \"throughout\": True,\n",
    "    \"additionally\": True,\n",
    "    \"moreover\": True,\n",
    "    \"furthermore\": True,\n",
    "    \"meanwhile\": True,\n",
    "    \"afterwards\": True,\n",
    "    # Irrelevant nouns\n",
    "    \"thing\": True,\n",
    "    \"thing's\": True,\n",
    "    \"things\": True,\n",
    "    \"stuff\": True,\n",
    "    \"other's\": True,\n",
    "    \"others\": True,\n",
    "    \"another's\": True,\n",
    "    \"total\": True,\n",
    "    \"true\": True,\n",
    "    \"false\": True,\n",
    "    \"none\": True,\n",
    "    \"way\": True,\n",
    "    \"kind\": True,\n",
    "    # Lettered numbers and order\n",
    "    \"zero\": True,\n",
    "    \"zeros\": True,\n",
    "    \"zeroes\": True,\n",
    "    \"one\": True,\n",
    "    \"ones\": True,\n",
    "    \"two\": True,\n",
    "    \"three\": True,\n",
    "    \"four\": True,\n",
    "    \"five\": True,\n",
    "    \"six\": True, \n",
    "    \"seven\": True,\n",
    "    \"eight\": True,\n",
    "    \"nine\": True,\n",
    "    \"ten\": True,\n",
    "    \"twenty\": True,\n",
    "    \"thirty\": True,\n",
    "    \"forty\": True,\n",
    "    \"fifty\": True,\n",
    "    \"sixty\": True,\n",
    "    \"seventy\": True,\n",
    "    \"eighty\": True,\n",
    "    \"ninety\": True,\n",
    "    \"hundred\": True,\n",
    "    \"hundreds\": True,\n",
    "    \"thousand\": True,\n",
    "    \"thousands\": True,\n",
    "    \"million\": True,\n",
    "    \"millions\": True,\n",
    "    \"first\": True,\n",
    "    \"last\": True,\n",
    "    \"second\": True,\n",
    "    \"third\": True,\n",
    "    \"fourth\": True,\n",
    "    \"fifth\": True,\n",
    "    \"sixth\": True,\n",
    "    \"seventh\": True,\n",
    "    \"eigth\": True,\n",
    "    \"ninth\": True,\n",
    "    \"tenth\": True,\n",
    "    \"firstly\": True,\n",
    "    \"secondly\": True,\n",
    "    \"thirdly\": True,\n",
    "    \"lastly\": True,\n",
    "    # Greetings and slang\n",
    "    \"hello\": True,\n",
    "    \"hi\": True,\n",
    "    \"hey\": True,\n",
    "    \"sup\": True,\n",
    "    \"yo\": True,\n",
    "    \"greetings\": True,\n",
    "    \"please\": True,\n",
    "    \"okay\": True,\n",
    "    \"ok\": True,\n",
    "    \"y'all\": True,\n",
    "    \"lol\": True,\n",
    "    \"rofl\": True,\n",
    "    \"thank\": True,\n",
    "    \"thanks\": True,\n",
    "    \"alright\": True,\n",
    "    \"kinda\": True,\n",
    "    \"dont\": True,\n",
    "    \"sorry\": True,\n",
    "    \"idk\": True,\n",
    "    \"tldr\": True,\n",
    "    \"tl\": True,\n",
    "    \"dr\": True,  #This means that dr (doctor) is a bad feature because of tl;dr\n",
    "    \"tbh\": True,\n",
    "    \"dude\": True,\n",
    "    \"tho\": True,\n",
    "    \"aka\": True,\n",
    "    \"plz\": True,\n",
    "    \"pls\": True,\n",
    "    \"bit\": True,\n",
    "    \"don\": True,\n",
    "\n",
    "    # Miscellaneous\n",
    "    \"www\": True,\n",
    "    \"https\": True,\n",
    "    \"http\": True,\n",
    "    \"com\": True,\n",
    "    \"etc\": True,\n",
    "    \"html\": True,\n",
    "    \"reddit\": True,\n",
    "    \"subreddit\": True,\n",
    "    \"subreddits\": True,\n",
    "    \"comments\": True,\n",
    "    \"reply\": True,\n",
    "    \"replies\": True,\n",
    "    \"thread\": True,\n",
    "    \"threads\": True,\n",
    "    \"post\": True,\n",
    "    \"posts\": True,\n",
    "    \"website\": True,\n",
    "    \"websites\": True,\n",
    "    \"web site\": True,\n",
    "    \"web sites\": True\n",
    "  }\n",
    "  return switcher.get(word,False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Bubble sort (descending order) for 2-dimensional list.\n",
    "def bubbleSort(list):\n",
    "  n = len(list) \n",
    "    \n",
    "  for i in range(n): \n",
    "      swapped = False\n",
    "\n",
    "      # Last i elements are already in place\n",
    "      for j in range(0, n-i-1): \n",
    "  \n",
    "          # loop through the array from 0 to n-i-1. Swap if\n",
    "          # the element found is less than the next element\n",
    "          if list[j][1] < list[j+1][1] : \n",
    "              list[j], list[j+1] = list[j+1], list[j] \n",
    "              swapped = True\n",
    "\n",
    "      # If no two elements were swapped \n",
    "      # by the inner loop, then break \n",
    "      if swapped == False: \n",
    "          break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# TODO: Leminization follow the tutorial stuff and call it after the two for loops\n",
    "\n",
    "# Remove all the irrelevant words from the entire X_words and Xtest_words\n",
    "for i in range(0, len(X_words)): # i is the current sample\n",
    "  j = 0\n",
    "  while j < len(X_words[i]):\n",
    "    if isIrrelevant(X_words[i][j]) or ((len(X_words[i][j]) < 3) and (X_words[i][j] != (\"money\" or \"number\"))):\n",
    "      X_words[i].remove(X_words[i][j])  #Remove irrelevant words from the training set\n",
    "      j -= 1\n",
    "    j += 1\n",
    "\n",
    "# NO NEED TO REMOVE THE IRRELEVANT WORDS IN Xtest FOR NOW\n",
    "# for i in range(0, len(Xtest_words)): # i is the current sample\n",
    "#   j = 0\n",
    "#   while j < len(Xtest_words[i]):\n",
    "#     if isIrrelevant(Xtest_words[i][j]) or ((len(Xtest_words[i][j]) < 3) and (Xtest_words[i][j] != (\"money\" or \"number\"))):\n",
    "#       Xtest_words[i].remove(Xtest_words[i][j])  #Remove irrelevant words from the training set\n",
    "#       j -= 1\n",
    "#    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['come', 'printable', 'quick', 'reference', 'sheet', 'foot', 'logh', 'leagues', 'adventure', 'share', 'googled', 'eyes', 'bleed', 'found', 'hex', \"gm's\", 'screen', 'char', 'gen', 'ubiquity', 'site', 'tia']\n"
     ]
    }
   ],
   "source": [
    "print(X_words[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert Selected Features into Numpy Array**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Select the number of desired features (words) and then return a numpy array X\n",
    "# with the top num_features most frequent features (words).\n",
    "# num_features is essentially the desired dictionary size of useful words.\n",
    "# The input disp_number is the number of top features to display.\n",
    "def featureSelection(X_words, Xtest_words, num_features, disp_number):\n",
    "    # Make a list of all the unique words in X_words and calculate their frequency.\n",
    "    temp1 = []     # List of all the unique words\n",
    "    temp2 = []     # List of all the words\n",
    "\n",
    "    for i in range(0, len(X_words)):  # i is the current sample\n",
    "        for j in range(0, len(X_words[i])):     # j is the current word number\n",
    "            temp2.append(X_words[i][j])\n",
    "\n",
    "            if X_words[i][j] not in temp1:    # Check for duplicates\n",
    "                temp1.append(X_words[i][j])\n",
    "\n",
    "    print(f\"Length of ordered list: {len(temp1)}\")\n",
    "\n",
    "    # Make a list of each unique word present and its frequency.\n",
    "    ordered_list = []\n",
    "    for x in range(0, len(temp1)):\n",
    "        ordered_list.append([temp1[x], temp2.count(temp1[x])])\n",
    "\n",
    "    # Sort the words in descending order of frequency. NOTE: Computationally heavy!\n",
    "    bubbleSort(ordered_list)\n",
    "\n",
    "    # Display the frequency of each unique word present.\n",
    "    # Note:  Max number of lines that can be displayed is 4999 in colab\n",
    "    for y in range (0,disp_number):\n",
    "        print('Frequency of', ordered_list[y][0], 'is:', ordered_list[y][1])\n",
    "\n",
    "    # Take the first num_features features and convert X_words into X\n",
    "    X = np.zeros((len(X_words),num_features))     # Numpy array of binary vectors\n",
    "    Xtest = np.zeros((len(Xtest_words),num_features)) #Numpy array of binary vectors for val or test\n",
    "\n",
    "    for i in range(0, X.shape[0]):         # i is the row of X_words and X\n",
    "        for j in range(0, X.shape[1]):       # j is the feature (word) index\n",
    "            if X_words[i].__contains__(ordered_list[j][0]):\n",
    "                X[i,j] = 1               # Assign 1 if X_words[i] contains the word\n",
    "            else:\n",
    "                X[i,j] = 0               # Assign 0 if X_words[i] does not contain the word\n",
    "\n",
    "    for i in range(0, Xtest.shape[0]):         # i is the row of Xtest_words and X\n",
    "        for j in range(0, Xtest.shape[1]):       # j is the feature (word) index\n",
    "            if Xtest_words[i].__contains__(ordered_list[j][0]):\n",
    "                Xtest[i,j] = 1               # Assign 1 if Xtest_wrods[i] contains the word\n",
    "            else:\n",
    "                Xtest[i,j] = 0               # Assign 0 if Xtest_words[i] does not contain the word\n",
    "\n",
    "    return X, Xtest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Convert X_words into the numpy array X of zeroes and ones.\n",
    "# Essentially, each sentence is now a binary vector of size num_features.  \n",
    "# Note: do not set num_features in featureSelection too high. 5000 is the \n",
    "# minimum accepted number of features in the competition.\n",
    "# X = featureSelection(X_words,5000,100)\n",
    "# NOTE: K-Fold does not make use of the X calculated here, this is only for testing purposes\n",
    "# print(f\"The shape of X is: {X.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Converting the Class Labels into a Numpy Array**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Convert the class labels to integers from 0 to 7 using a dictionary\n",
    "def labelToNumber (label):\n",
    "  switcher = {\n",
    "    \"rpg\": 0,\n",
    "    \"anime\": 1,\n",
    "    \"datascience\": 2,\n",
    "    \"hardware\": 3,\n",
    "    \"cars\": 4,\n",
    "    \"gamernews\": 5,\n",
    "    \"gamedev\": 6,\n",
    "    \"computers\": 7,\n",
    "  }\n",
    "  return switcher.get(label,\"Invalid class label\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our labels vector Y: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert the class labels into a numpy array named Y.\n",
    "# Each entry in Y should still match the corresponding row in X.\n",
    "Y = np.zeros((len(training_set_out),1))\n",
    "\n",
    "for i in range(0, Y.shape[0]):\n",
    "  # Convert the class labels to a number between 0 and 7\n",
    "  label_number = labelToNumber(training_set_out[i])   \n",
    "\n",
    "  if label_number != \"Invalid class label\":\n",
    "    Y[i,0] = label_number\n",
    "  else: \n",
    "    print(\"Invalid class label!\")\n",
    "      \n",
    "print(f\"The shape of our labels vector Y: {Y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Probabilities**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Calculate the probability of Y = 1.\n",
    "# Returns a column vector for which the ith entry is P(Yi=1)\n",
    "# and i refers to a class label.\n",
    "def probY(Y, num_classes):\n",
    "  prob = np.zeros((num_classes,1))  #Probability vector P(Yi=1)\n",
    "    \n",
    "  for i in range(0,Y.shape[0]):\n",
    "    # Assumption: labels are integers ranging from 0 to num_labels - 1\n",
    "    for label in range(0, num_classes):\n",
    "      if Y[i,0] == label:\n",
    "        prob[label,0] += 1\n",
    "      elif Y[i,0] > (num_classes - 1):\n",
    "        print(\"Y at index \" + str(i) + \" is an invalid class label\")\n",
    "        break\n",
    "  # Divide by the total # of labels input labels Y\n",
    "  prob = prob/Y.shape[0]\n",
    "  return prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n",
      "(8, 1)\n",
      "[[0.174 ]\n",
      " [0.121 ]\n",
      " [0.2065]\n",
      " [0.1295]\n",
      " [0.184 ]\n",
      " [0.07  ]\n",
      " [0.0855]\n",
      " [0.0295]]\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "probOfAllClassLabels = probY(Y,8)\n",
    "print(probOfAllClassLabels.shape)\n",
    "print(probOfAllClassLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Calculate the probability of X = 1 given a class label Yi (number).\n",
    "# Returns a row vector for which the jth entry is P(Xj=1|Yi)\n",
    "# and j refers to a feature.\n",
    "# Note: not implemented with the bias term in mind.\n",
    "def probXGivenYi(X, Y, label):\n",
    "  prob = np.zeros((1,X.shape[1]))  # Conditional probability vector P(Xj=1|Yi)\n",
    "  denominator = 0                  # Number of times label Yi appears in Y\n",
    "\n",
    "  for i in range(0, X.shape[0]):\n",
    "    if Y[i,0] == label:\n",
    "      denominator += 1\n",
    "      prob = prob + X[i,:]\n",
    "\n",
    "  # Laplace smoothing\n",
    "  prob = prob + np.ones((1,X.shape[1]))\n",
    "  denominator += 2\n",
    "\n",
    "  prob = prob/denominator\n",
    "  return prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# # Finding the conditional probability of features of X given we know its of a specific label\n",
    "# probXgivenYi = probXGivenYi(X, Y, 1)\n",
    "# print(f\"Shape of P(Xj=1/Yi) is: {probXgivenYi.shape}\")\n",
    "# print(probXgivenYi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Superclass for Bernouilli Naive Bayes Classifiers\n",
    "class Bernoulli_NB(object):\n",
    "\n",
    "\n",
    "    #Class constructor\n",
    "    def __init__(self, num_classes,LaplaceSmooth=True):\n",
    "      self.num_classes = num_classes\n",
    "      self.condProb = None\n",
    "      self.priorProb = None\n",
    "      self.LaplaceSmoothening = LaplaceSmooth\n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "\n",
    "    # Calculate the probability of Y = 1.\n",
    "    # Returns a column vector for which the ith entry is P(Yi=1)\n",
    "    # and i refers to a class label.\n",
    "    def probY(self, Y):\n",
    "      num_labels = self.num_classes\n",
    "      prob = np.zeros((num_labels,1))  #Probability vector P(Yi=1)\n",
    "\n",
    "      for i in range(0,Y.shape[0]):\n",
    "        # Assumption: labels are integers ranging from 0 to num_labels - 1\n",
    "        for label in range(0, num_labels):\n",
    "          if Y[i,0] == label:\n",
    "            prob[label,0] += 1\n",
    "          elif Y[i,0] > (num_labels - 1):\n",
    "            print(\"Y at index \" + str(i) + \" is an invalid class label\")\n",
    "            break\n",
    "      # Divide by the total # of labels input labels Y\n",
    "      prob = prob/Y.shape[0]\n",
    "      return prob\n",
    "\n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    # Calculate the probability of X = 1 given a class label Yi (number).\n",
    "    # Returns a row vector for which the jth entry is P(Xj=1|Yi)\n",
    "    # and j refers to a feature.\n",
    "    # Note: not implemented with the bias term in mind.\n",
    "    def probXGivenYi(self, X, Y, label):\n",
    "      prob = np.zeros((1,X.shape[1]))  # Conditional probability vector P(Xj=1|Yi)\n",
    "      denominator = 0                  # Number of times label Yi appears in Y\n",
    "\n",
    "      for i in range(0, X.shape[0]):\n",
    "        if Y[i,0] == label:\n",
    "          denominator += 1\n",
    "          prob = prob + X[i,:]\n",
    "\n",
    "      # Laplace smoothing\n",
    "      if(self.LaplaceSmoothening):\n",
    "        prob = prob + np.ones((1,X.shape[1]))\n",
    "        denominator += 2\n",
    "\n",
    "      prob = prob/denominator\n",
    "      return prob\n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "    # Write the Bernoulli Naive  Bayes Method Here\n",
    "    def fit(self, Xtrain, Y):\n",
    "        print('Starting the fit function::::')\n",
    "        t1 = time.time()\n",
    "\n",
    "        self.condProb = np.zeros((self.num_classes,Xtrain.shape[1]))\n",
    "        t2 =time.time()\n",
    "        self.priorProb = self.probY(Y)\n",
    "        print('Time taken for Pior probs function:::', time.time()-t2 )\n",
    "\n",
    "        t3 = time.time()\n",
    "        for c in range(self.num_classes):\n",
    "            self.condProb[c,:] = self.probXGivenYi(Xtrain, Y, c)\n",
    "        print('Time taken for Condtional Prob:::', time.time()-t3)\n",
    "        print('Total time by fit function:::', time.time()-t1 )\n",
    "    ####################################################################################################\n",
    "    ####################################################################################################\n",
    "                            #NON OPTIMISED BERNOULLI #\n",
    "    # def predict(self,Xtest):\n",
    "    #\n",
    "    #     predLabel = np.zeros((Xtest.shape[0],1))\n",
    "    #     prosteriorProb = np.zeros((Xtest.shape[0],8))\n",
    "    #\n",
    "    #     for d in range(Xtest.shape[0]):\n",
    "    #         for c in range(8):\n",
    "    #             prosteriorProb[d,c] = np.log10(self.priorProb[c,0])\n",
    "    #             for index in range(Xtest.shape[1]):\n",
    "    #                 if(Xtest[d,index] == 1):\n",
    "    #                     prosteriorProb[d,c] += np.log10(self.condProb[c,index])\n",
    "    #                 else:\n",
    "    #                     prosteriorProb[d,c] += np.log10(1 - self.condProb[c,index])\n",
    "    #\n",
    "    #                 # print(self.condProb[c, index])\n",
    "    #\n",
    "    #         predLabel[d,0] = np.argmax(prosteriorProb[d,:])\n",
    "    #         # print(prosteriorProb[d, :])\n",
    "    #         # print(predLabel[d,0])\n",
    "    #         # if d == 5:\n",
    "    #         #     return\n",
    "    #\n",
    "    #     return predLabel\n",
    "    ####################################################################################\n",
    "    ####################################################################################\n",
    "                            # OPTIMISED BERNOULLI #\n",
    "    def predict(self,Xtest):\n",
    "        print('Starting the Predicting Function: tick tock... tick tock')\n",
    "        start_time = time.time()\n",
    "        predLabel = np.zeros((Xtest.shape[0],1))\n",
    "        prosteriorProb = np.zeros((Xtest.shape[0],self.num_classes))\n",
    "        for d in range(Xtest.shape[0]):\n",
    "            for c in range(self.num_classes):\n",
    "                prosteriorProb[d,c] = np.log10(self.priorProb[c,0])\n",
    "                # for index in range(Xtest.shape[1]):\n",
    "                #     if(Xtest[d,index] == 1):\n",
    "                #         prosteriorProb[d,c] += np.log10(self.condProb[c,index])\n",
    "                #     else:\n",
    "                #         prosteriorProb[d,c] += np.log10(1 - self.condProb[c,index])\n",
    "                Z = Xtest[d,:]\n",
    "                one_ind = np.where(Z==1)[0]\n",
    "                # print(one_ind)\n",
    "                # zero_ind = np.where(Z==0)[0]\n",
    "                zero_ind = np.delete(np.arange(0,Xtest.shape[0]),one_ind,0)\n",
    "                # print(\"Done With finding 0s\")\n",
    "                row_ones = np.ones((1,zero_ind.shape[0]))\n",
    "\n",
    "                prosteriorProb[d,c] += np.sum(np.log10(self.condProb[c,one_ind]))\n",
    "                prosteriorProb[d,c] +=  np.sum(np.log10(row_ones-self.condProb[c,zero_ind]))\n",
    "                    # print(self.condProb[c, index])\n",
    "\n",
    "            predLabel[d,0] = np.argmax(prosteriorProb[d,:])\n",
    "            # print(prosteriorProb[d, :])\n",
    "            # print(predLabel[d,0])\n",
    "            # if d == 5:\n",
    "            #     return\n",
    "        print('Time taken for predict function::: {} ', {time.time()-start_time})\n",
    "        return predLabel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SKLearn Classifiers: Decision Trees & Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Function returns a desired SKLearn classifier at run time\n",
    "# Note: classifierEnum can take two values 0 or 1 read code to know which classifier\n",
    "# you would like to create at run time\n",
    "def createSKLearnClassifier(classifierEnum):\n",
    "    # Switching to create different sk learn classifiers at run time\n",
    "    if classifierEnum == 0 :\n",
    "        print(f\"Created a DecisionTreeClassifier!\\n\")\n",
    "        return DecisionTreeClassifier()\n",
    "    elif classifierEnum == 1:\n",
    "        print(f\"Created a LogisticRegressionClassifier!\\n\")\n",
    "        return LogisticRegression()\n",
    "    elif classifierEnum == 2:\n",
    "        print(f\"Created a linear SVM classifier (supports high dim data and samples)!\\n\")\n",
    "        return LinearSVC()\n",
    "    elif classifierEnum == 3:\n",
    "        print(f\"Created a SVM classifier with SGD training!\\n\")\n",
    "        return SGDClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-Fold Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation function\n",
    "def run_K_Fold_CrossValidation(X_words, Y, numFeatures, classifier, numFolds=None):\n",
    "\n",
    "    # Convert X_words into a 1D numpy array for ease of indexing later\n",
    "    X_words_numpy = np.array(X_words)\n",
    "\n",
    "    \"\"\"Starting K-Fold Cross Validation\"\"\"\n",
    "    # Create a dictionary to hold our fold accuracies\n",
    "    fold_Accuracy_Dict = {}\n",
    "\n",
    "    # Create sklearn's K-Fold instance\n",
    "    kf = KFold(n_splits=numFolds)\n",
    "\n",
    "    # Find out how many splitting iterations\n",
    "    print(f\"Number of splitting iterations: {kf.get_n_splits(Y)}\\n\")\n",
    "    # TO UPDATE: print(f\"Number of splitting iterations: {kf.get_n_splits(Y)}\\n\")\n",
    "\n",
    "    # Fold Iteration count\n",
    "    foldCount = 0\n",
    "\n",
    "    # Fold error sum tracker\n",
    "    foldErrorSum = 0\n",
    "\n",
    "    # Fold accuracy tracker\n",
    "    foldAccuracySum = 0\n",
    "\n",
    "    # K-Fold loop\n",
    "    for training_indices, validation_indices in kf.split(Y):\n",
    "    # TO UPDATE: for training_indices, validation_indices in kf.split(Y):\n",
    "\n",
    "        print(f\"Starting fold {foldCount + 1}.....\")\n",
    "        # print(\"Training: \", training_indices, \"Validation: \", validation_indices)\n",
    "\n",
    "        # Slicing our data to get current training and current validation sets\n",
    "        curFoldTraining = X_words_numpy[training_indices]\n",
    "        curFoldTrainingLabels = Y[training_indices,:]\n",
    "        curFoldValidation = X_words_numpy[validation_indices]\n",
    "        curFoldValidationLabels = Y[validation_indices,:]\n",
    "\n",
    "        # print(\"Current fold training: \\n\", curFoldTraining) # if you want to see the sliced array for training\n",
    "        # print(f\"Current fold training shape: {curFoldTraining.shape}\")\n",
    "        # print(\"Current fold validation: \\n\", curFoldValidation) # if you want to see the sliced array for validation\n",
    "        # print(f\"Current fold validation shape: {curFoldValidation.shape}\")\n",
    "\n",
    "        # converting back into lists from numpy array\n",
    "        curFoldTraining = list(curFoldTraining)\n",
    "        curFoldValidation = list(curFoldValidation)\n",
    "        # print(curFoldTraining)\n",
    "        # print(f\"Current training length as list: {len(curFoldTraining)}\")\n",
    "        # print(f\"Current validation length as list: {len(curFoldValidation)}\")\n",
    "\n",
    "        # Converting into numpy arrays for the training and validation sets and also doing featureSelection\n",
    "        Xtrain, Xval = featureSelection(curFoldTraining, curFoldValidation, numFeatures, 0)\n",
    "\n",
    "        # Fit our model with training\n",
    "        \"\"\"TODO: use our naive bayes classifier's fit function to fit our model to our training set\"\"\"\n",
    "        classifier.fit(Xtrain, curFoldTrainingLabels)\n",
    "        # TO UPDATE: classifier.fit(Xtrain, curFoldTrainingLabels)\n",
    "\n",
    "        # Predict the labels here\n",
    "        \"\"\"TODO: use our predict function to predict the labels on the validation set\"\"\"\n",
    "        curFoldPredictedLabels = classifier.predict(Xval)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        \"\"\"TODO: find accuracy\"\"\"\n",
    "        count = 0\n",
    "        for i in range(0, curFoldPredictedLabels.shape[0]):\n",
    "            if curFoldValidationLabels[i] == curFoldPredictedLabels[i]:\n",
    "                count += 1\n",
    "        currentFoldAccuracy = (count/curFoldPredictedLabels.shape[0])*100\n",
    "        print(f\"Accuracy for fold {foldCount + 1}: {currentFoldAccuracy}%\\n\")\n",
    "\n",
    "        # Add the accuracy of this fold to the dictionary\n",
    "        fold_Accuracy_Dict[str(foldCount + 1)] = float(currentFoldAccuracy)\n",
    "\n",
    "        # Update fold error tracker & fold accuracy tracker\n",
    "        foldErrorSum = foldErrorSum + (100.0 - currentFoldAccuracy)\n",
    "        foldAccuracySum = foldAccuracySum + currentFoldAccuracy\n",
    "\n",
    "        # Update fold number\n",
    "        foldCount += 1\n",
    "\n",
    "    # Graph the fold accuracies with the dictionary\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.bar(fold_Accuracy_Dict.keys(), fold_Accuracy_Dict.values(), 0.3, color='b')\n",
    "    plt.xlabel('Fold Number')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.title(\"K-Fold Accuracy Distribution of Current Model\")\n",
    "    plt.show()\n",
    "\n",
    "    # Display this model's avg accuracy for the K-Fold\n",
    "    avgAccuracyOfThisModel = float(float(foldAccuracySum)/float(foldCount))\n",
    "    print(f\"\\nAvg accuracy for this model is: {avgAccuracyOfThisModel} %\")\n",
    "\n",
    "    # Display this model's avg error for the K-Fold\n",
    "    avgErrorOfThisModel = float(float(foldErrorSum)/float(foldCount))\n",
    "    print(f\"Avg error for this model is: {avgErrorOfThisModel} %\\n\")\n",
    "\n",
    "    # Returning the avg error, fold accuracy dictionary, and model accuracy\n",
    "    return avgErrorOfThisModel, avgAccuracyOfThisModel, fold_Accuracy_Dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splitting iterations: 5\n",
      "\n",
      "Starting fold 1.....\n",
      "Length of ordered list: 13396\n",
      "Starting the fit function::::\n",
      "Time taken for Pior probs function::: 0.011912822723388672\n",
      "Time taken for Condtional Prob::: 0.010971307754516602\n",
      "Total time by fit function::: 0.022884130477905273\n",
      "Starting the Predicting Function: tick tock... tick tock\n",
      "Time taken for predict function::: {}  {0.20949625968933105}\n",
      "Accuracy for fold 1: 70.5%\n",
      "\n",
      "Starting fold 2.....\n",
      "Length of ordered list: 13349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-db8a630cfebc>:118: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  zero_ind = np.delete(np.arange(0,Xtest.shape[0]),one_ind,0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-25-4e90b723b938>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Talk about feature selection function with alex tomorrow: prone to failure depending on how many features we choose\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mrun_K_Fold_CrossValidation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_words\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumFolds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-d0a595ffa6b0>\u001B[0m in \u001B[0;36mrun_K_Fold_CrossValidation\u001B[1;34m(X_words, Y, numFeatures, classifier, numFolds)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m         \u001B[1;31m# Converting into numpy arrays for the training and validation sets and also doing featureSelection\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m         \u001B[0mXtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mXval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfeatureSelection\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurFoldTraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurFoldValidation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumFeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[1;31m# Fit our model with training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-14-5b12e776728f>\u001B[0m in \u001B[0;36mfeatureSelection\u001B[1;34m(X_words, Xtest_words, num_features, disp_number)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;31m# Sort the words in descending order of frequency. NOTE: Computationally heavy!\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m     \u001B[0mbubbleSort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mordered_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;31m# Display the frequency of each unique word present.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-11-e8c33bd80038>\u001B[0m in \u001B[0;36mbubbleSort\u001B[1;34m(list)\u001B[0m\n\u001B[0;32m     11\u001B[0m           \u001B[1;31m# loop through the array from 0 to n-i-1. Swap if\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m           \u001B[1;31m# the element found is less than the next element\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m           \u001B[1;32mif\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m               \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m               \u001B[0mswapped\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Creating naive bayes classifier\n",
    "nb = Bernoulli_NB(8)\n",
    "\n",
    "# Talk about feature selection function with alex tomorrow: prone to failure depending on how many features we choose\n",
    "run_K_Fold_CrossValidation(X_words, Y, 1000, nb, numFolds=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Superclass for Bernouilli Naive Bayes Classifiers\n",
    "# class Bernoulli_NB():\n",
    "#     #Class constructor\n",
    "#     def __int__(self,num_classes):\n",
    "#       self.num_classes = num_classes\n",
    "#       self.condProb = None\n",
    "#       self.priorProb = None\n",
    "#\n",
    "#     ####################################################################################################\n",
    "#     ####################################################################################################\n",
    "#\n",
    "#     # Calculate the probability of Y = 1.\n",
    "#     # Returns a column vector for which the ith entry is P(Yi=1)\n",
    "#     # and i refers to a class label.\n",
    "#     def probY(self,Y):\n",
    "#       num_labels = self.num_classes\n",
    "#       prob = np.zeros((num_labels,1))  #Probability vector P(Yi=1)\n",
    "#\n",
    "#       for i in range(0,Y.shape[0]):\n",
    "#         # Assumption: labels are integers ranging from 0 to num_labels - 1\n",
    "#         for label in range(0, num_labels):\n",
    "#           if Y[i,0] == label:\n",
    "#             prob[label,0] += 1\n",
    "#           elif Y[i,0] > (num_labels - 1):\n",
    "#             print(\"Y at index \" + str(i) + \" is an invalid class label\")\n",
    "#             break\n",
    "#       # Divide by the total # of labels input labels Y\n",
    "#       prob = prob/Y.shape[0]\n",
    "#       return prob\n",
    "#\n",
    "#     ####################################################################################################\n",
    "#     ####################################################################################################\n",
    "#     # Calculate the probability of X = 1 given a class label Yi (number).\n",
    "#     # Returns a row vector for which the jth entry is P(Xj=1|Yi)\n",
    "#     # and j refers to a feature.\n",
    "#     # Note: not implemented with the bias term in mind.\n",
    "#     def probXGivenYi(self, X, Y, label):\n",
    "#       prob = np.zeros((1,X.shape[1]))  # Conditional probability vector P(Xj=1|Yi)\n",
    "#       denominator = 0                  # Number of times label Yi appears in Y\n",
    "#\n",
    "#       for i in range(0, X.shape[0]):\n",
    "#         if Y[i,0] == label:\n",
    "#           denominator += 1\n",
    "#           prob = prob + X[i,:]\n",
    "#\n",
    "#       # Laplace smoothing\n",
    "#       prob = prob + np.ones((1,X.shape[1]))\n",
    "#       denominator += 2\n",
    "#\n",
    "#       prob = prob/denominator\n",
    "#       return prob\n",
    "#     ####################################################################################################\n",
    "#     ####################################################################################################\n",
    "#     # Write the Bernoulli Naive  Bayes Method Here\n",
    "#     def fit(self,Xtrain,Y):\n",
    "#         self.condProb = np.zeros((self.num_classes,Xtrain.shape[1]))\n",
    "#         self.priorProb = self.probY(Y, self.num_classes)\n",
    "#\n",
    "#         for c in range(self.num_classes):\n",
    "#             self.condProb[c,:] = self.probXGivenYi(Xtrain, Y, c)\n",
    "#\n",
    "#     ####################################################################################################\n",
    "#     ####################################################################################################\n",
    "#\n",
    "#     def predict(self,Xtest):\n",
    "#\n",
    "#         predLabel = np.zeros((Xtest.shape[0],1))\n",
    "#         prosteriorProb = np.zeros((Xtest.shape[0],8))\n",
    "#\n",
    "#         for d in range(Xtest.shape[0]):\n",
    "#             for c in range(8):\n",
    "#                  for index in range(Xtest.shape[1]):\n",
    "#                      prosteriorProb[d,c] = np.log10(self.priorProb[1,c])\n",
    "#\n",
    "#                      if(Xtest(d,index) ==1):\n",
    "#                          prosteriorProb[d,c] += np.log10(self.condProb[c,index])\n",
    "#                      else:\n",
    "#                          prosteriorProb[d,c] += np.log10(1 - self.condProb[c,index])\n",
    "#             predLabel[d,1] = np.argmax(prosteriorProb[d,:])\n",
    "#         return predLabel\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECSE551_Project2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}